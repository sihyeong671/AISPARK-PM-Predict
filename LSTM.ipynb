{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "  def __init__(self, X, y):\n",
    "    self.X = X\n",
    "    self.y = y\n",
    "        \n",
    "  def __getitem__(self, index):\n",
    "    return self.X[index], self.y[index]\n",
    "    \n",
    "  def __len__(self):\n",
    "    return len(self.X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "  def __init__(self, num_classes, num_layers, input_size, hidden_size, device):\n",
    "    super().__init__()\n",
    "    self.num_classes = num_classes\n",
    "    self.num_layer = num_layers\n",
    "    self.input_size = input_size\n",
    "    self.hidden_size = hidden_size\n",
    "    self.device = device\n",
    "    \n",
    "    self.lstm = nn.LSTM(\n",
    "      input_size=input_size,\n",
    "      hidden_size=hidden_size,\n",
    "      num_layers=num_layers,\n",
    "      batch_first=True,\n",
    "      dropout=0.2)\n",
    "    self.fc_1 = nn.Linear(hidden_size, 128)\n",
    "    self.fc_2 = nn.Linear(128, num_classes)\n",
    "    self.relu = nn.ReLU(inplace=True)\n",
    "    \n",
    "  def forward(self, x):\n",
    "    h_0 = torch.zeros(self.num_layer, x.size(0), self.hidden_size, device=self.device)\n",
    "    c_0 = torch.zeros(self.num_layer, x.size(0), self.hidden_size, device=self.device)\n",
    "    \n",
    "    output, (hn, cn) = self.lstm(x, (h_0, c_0))\n",
    "    hn = hn.view(-1, self.hidden_size)\n",
    "    out = self.relu(hn)\n",
    "    out = self.fc_1(out)\n",
    "    out = self.relu(out)\n",
    "    out = self.fc_2(out)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "  def __init__(self, path):\n",
    "    self.path = path\n",
    "    self.n_step_in = 24 * 2\n",
    "    self.n_step_out = 24 * 3\n",
    "    \n",
    "    self.n_epochs = 100\n",
    "    self.lr = 0.001\n",
    "    self.input_size = 6\n",
    "    self.hidden_size = 8\n",
    "    self.num_layers = 1\n",
    "    self.num_classes = 24*3\n",
    "    \n",
    "    self.device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "    \n",
    "  def set_up(self):\n",
    "    df = pd.read_csv(\"./dataset/CUSTOM_v0/공주.csv\")\n",
    "    df.drop(columns=[\"연도\", \"일시\", \"측정소\"], inplace=True)\n",
    "\n",
    "    scaler = preprocessing.MinMaxScaler()\n",
    "    scaled_np = scaler.fit_transform(df.values)\n",
    "    scaled_df = pd.DataFrame(scaled_np, columns=df.columns)\n",
    "    X, y = self._split_sequences(\n",
    "      input_seq=scaled_df.values,\n",
    "      output_seq=scaled_df[\"PM2.5\"].values,\n",
    "      n_step_in=self.n_step_in,\n",
    "      n_step_out=self.n_step_out)\n",
    "    \n",
    "    X_train = X[:-3000]\n",
    "    X_val = X[-3000:]\n",
    "    \n",
    "    y_train = y[:-3000]\n",
    "    y_val = y[-3000:]\n",
    "    \n",
    "    train_dataset = CustomDataset(X_train, y_train)\n",
    "    val_dataset = CustomDataset(X_val, y_val)\n",
    "\n",
    "    self.train_dataloader = DataLoader(\n",
    "      dataset=train_dataset,\n",
    "      shuffle=True,\n",
    "      batch_size=128,\n",
    "    )\n",
    "    \n",
    "    self.val_dataloader = DataLoader(\n",
    "      dataset=val_dataset,\n",
    "      shuffle=False,\n",
    "      batch_size=256,\n",
    "    )\n",
    "    \n",
    "  def _split_sequences(self, input_seq, output_seq, n_step_in, n_step_out):\n",
    "    X, y = list(), list()\n",
    "    for i in range(len(input_seq)):\n",
    "      end_idx = i + n_step_in\n",
    "      out_end_idx = end_idx + n_step_out\n",
    "      if out_end_idx > len(input_seq):\n",
    "        break\n",
    "      seq_x, seq_y = input_seq[i:end_idx], output_seq[end_idx:out_end_idx]\n",
    "      X.append(seq_x)\n",
    "      y.append(seq_y)\n",
    "    return np.array(X), np.array(y)\n",
    "  \n",
    "\n",
    "  def train(self):\n",
    "    model = LSTM(\n",
    "      num_classes=self.num_classes,\n",
    "      num_layers=self.num_layers,\n",
    "      input_size=self.input_size,\n",
    "      hidden_size=self.hidden_size,\n",
    "      device=self.device).to(self.device)\n",
    "    \n",
    "    loss_fn = nn.MSELoss().to(self.device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=self.lr)\n",
    "    \n",
    "    print(\"TRAIN START\")\n",
    "    for epoch in range(1, self.n_epochs+1):\n",
    "      model.train()\n",
    "      train_loss = []\n",
    "      for batch in self.train_dataloader:\n",
    "        X, y = batch\n",
    "        X = X.float().to(self.device)\n",
    "        y = y.float().to(self.device)\n",
    "        outputs = model.forward(X)\n",
    "        optimizer.zero_grad()\n",
    "        loss = loss_fn(outputs, y)\n",
    "        train_loss.append(loss.item())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "      \n",
    "      model.eval()\n",
    "      with torch.no_grad():\n",
    "        val_loss = []\n",
    "        for batch in self.val_dataloader:\n",
    "          X, y = batch\n",
    "          # numpy 기본 자료형은 float64이므로 float32에 매칭시켜줘야함\n",
    "          X = X.float().to(self.device)\n",
    "          y = y.float().to(self.device)\n",
    "          outputs = model.forward(X)\n",
    "          loss = loss_fn(outputs, y)\n",
    "          val_loss.append(loss.item())\n",
    "      \n",
    "      \n",
    "      if epoch % 10 == 0:\n",
    "        # 데이터에 nan값이 있는 경우 loss가 계속 nan값이 나옴\n",
    "        print(f\"Epoch: {epoch},\\\n",
    "          train loss: {sum(train_loss)/len(train_loss):.5f},\\\n",
    "          val loss: {sum(val_loss)/len(val_loss):.5f}\")\n",
    "        \n",
    "    print(\"TRAIN FIN\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(path=\"./dataset/CUSTOM_v0/공주.csv\")\n",
    "trainer.set_up()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\BSH\\.virtualenvs\\aifactory-cLCMmIYn\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN START\n",
      "Epoch: 10,          train loss: 0.006,          val loss: 0.006\n",
      "Epoch: 20,          train loss: 0.005,          val loss: 0.005\n",
      "Epoch: 30,          train loss: 0.005,          val loss: 0.005\n",
      "Epoch: 40,          train loss: 0.005,          val loss: 0.005\n",
      "Epoch: 50,          train loss: 0.005,          val loss: 0.005\n",
      "Epoch: 60,          train loss: 0.005,          val loss: 0.006\n",
      "Epoch: 70,          train loss: 0.005,          val loss: 0.005\n",
      "Epoch: 80,          train loss: 0.005,          val loss: 0.005\n",
      "Epoch: 90,          train loss: 0.005,          val loss: 0.005\n",
      "Epoch: 100,          train loss: 0.005,          val loss: 0.005\n",
      "TRAIN FIN\n"
     ]
    }
   ],
   "source": [
    "mdl = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>연도</th>\n",
       "      <th>일시</th>\n",
       "      <th>측정소</th>\n",
       "      <th>PM2.5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>01-01 00:00</td>\n",
       "      <td>공주</td>\n",
       "      <td>0.060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>01-01 01:00</td>\n",
       "      <td>공주</td>\n",
       "      <td>0.064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>01-01 02:00</td>\n",
       "      <td>공주</td>\n",
       "      <td>0.072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>01-01 03:00</td>\n",
       "      <td>공주</td>\n",
       "      <td>0.064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>01-01 04:00</td>\n",
       "      <td>공주</td>\n",
       "      <td>0.056</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   연도           일시 측정소  PM2.5\n",
       "0   4  01-01 00:00  공주  0.060\n",
       "1   4  01-01 01:00  공주  0.064\n",
       "2   4  01-01 02:00  공주  0.072\n",
       "3   4  01-01 03:00  공주  0.064\n",
       "4   4  01-01 04:00  공주  0.056"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv(\"./dataset/TEST_INPUT/공주.csv\")\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predict = mdl()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aifactory-cLCMmIYn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
